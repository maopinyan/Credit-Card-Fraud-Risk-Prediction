{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portfolio_id</th>\n",
       "      <th>product_term_credit_limit</th>\n",
       "      <th>NP</th>\n",
       "      <th>cash_intent</th>\n",
       "      <th>ALJ0300</th>\n",
       "      <th>ALJ0316</th>\n",
       "      <th>ALJ0416</th>\n",
       "      <th>ALJ5030</th>\n",
       "      <th>ALJ5320</th>\n",
       "      <th>ALJ5730</th>\n",
       "      <th>...</th>\n",
       "      <th>TSTU0910</th>\n",
       "      <th>TSTU2906</th>\n",
       "      <th>TSTU2907</th>\n",
       "      <th>TSTU2908</th>\n",
       "      <th>TSTU3906</th>\n",
       "      <th>TSTU3907</th>\n",
       "      <th>TSTU3908</th>\n",
       "      <th>TSTU4906</th>\n",
       "      <th>TSTU4907</th>\n",
       "      <th>TSTU4908</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_nb</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1908</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33521</td>\n",
       "      <td>50283</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1908</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>999999998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>...</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1908</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999999997</td>\n",
       "      <td>999999997</td>\n",
       "      <td>999999997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1908</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>999999998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>...</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1908</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999999997</td>\n",
       "      <td>999999997</td>\n",
       "      <td>999999997</td>\n",
       "      <td>...</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>999999998.0</td>\n",
       "      <td>999999998.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           portfolio_id  product_term_credit_limit  NP  cash_intent  ALJ0300  \\\n",
       "record_nb                                                                      \n",
       "1                  1908                        500   0            0        2   \n",
       "2                  1908                        500   0            0        0   \n",
       "3                  1908                        500   0            0        1   \n",
       "4                  1908                        500   0            0        0   \n",
       "5                  1908                        500   0            1        2   \n",
       "\n",
       "           ALJ0316  ALJ0416    ALJ5030    ALJ5320    ALJ5730  ...  \\\n",
       "record_nb                                                     ...   \n",
       "1                1        1      33521      50283          0  ...   \n",
       "2               98       98  999999998  999999998  999999998  ...   \n",
       "3                0        0  999999997  999999997  999999997  ...   \n",
       "4               98       98  999999998  999999998  999999998  ...   \n",
       "5                0        0  999999997  999999997  999999997  ...   \n",
       "\n",
       "              TSTU0910  TSTU2906     TSTU2907     TSTU2908  TSTU3906  \\\n",
       "record_nb                                                              \n",
       "1                  0.0       0.0          0.0          0.0       0.0   \n",
       "2          999999998.0      98.0  999999998.0  999999998.0      98.0   \n",
       "3                  0.0       0.0          0.0          0.0       0.0   \n",
       "4          999999998.0      98.0  999999998.0  999999998.0      98.0   \n",
       "5          999999998.0      98.0  999999998.0  999999998.0      98.0   \n",
       "\n",
       "              TSTU3907     TSTU3908  TSTU4906     TSTU4907     TSTU4908  \n",
       "record_nb                                                                \n",
       "1                  0.0          0.0       0.0          0.0          0.0  \n",
       "2          999999998.0  999999998.0      98.0  999999998.0  999999998.0  \n",
       "3                  0.0          0.0       0.0          0.0          0.0  \n",
       "4          999999998.0  999999998.0      98.0  999999998.0  999999998.0  \n",
       "5          999999998.0  999999998.0      98.0  999999998.0  999999998.0  \n",
       "\n",
       "[5 rows x 2329 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fraud_risk_dataset.csv', header=0, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, normalize, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the null values\n",
    "ccfullData = df.fillna(0)\n",
    "ccfullData.drop('NP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the categorical values to later convert these variables using one hot encoding and keeping only the continuous numeric variables for standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b = ccfullData.drop(['portfolio_id','product_term_credit_limit','cash_intent','ALL9950','ALL9951','GLBDECS','ALL6310','ALL6320','MTF6326'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19030, 2319)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using **RobustScaler()**, we can remove the outliers and then use either StandardScaler for preprocessing the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaled_x_b = scaler.fit_transform(x_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_ccfullData = scaler.fit_transform(scaled_x_b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19030, 2319)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_df = pd.DataFrame(scaled_ccfullData)\n",
    "scaler_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables are converted to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = OneHotEncoder(sparse=False, drop= 'first', handle_unknown = 'error') \n",
    "\n",
    "onehot.fit(ccfullData.portfolio_id.to_numpy().reshape(-1,1))\n",
    "year_onehot = onehot.transform(ccfullData.portfolio_id.to_numpy().reshape(-1,1))\n",
    "year_onehot = pd.DataFrame(year_onehot, columns= onehot.get_feature_names(['portfolio_id']))\n",
    "\n",
    "onehot.fit(ccfullData.product_term_credit_limit.to_numpy().reshape(-1,1))\n",
    "product_term_onehot = onehot.transform(ccfullData.product_term_credit_limit.to_numpy().reshape(-1,1))\n",
    "product_term_onehot = pd.DataFrame(product_term_onehot, columns= onehot.get_feature_names(['product_term_credit_limit']))\n",
    "\n",
    "onehot.fit(ccfullData.cash_intent.to_numpy().reshape(-1,1))\n",
    "cash_intent_onehot = onehot.transform(ccfullData.cash_intent.to_numpy().reshape(-1,1))\n",
    "cash_intent_onehot = pd.DataFrame(cash_intent_onehot, columns= onehot.get_feature_names(['cash_intent']))\n",
    "\n",
    "#Credit bureau attributes with Flag unit\n",
    "onehot.fit(ccfullData.ALL9950.to_numpy().reshape(-1,1))\n",
    "ALL9950_onehot = onehot.transform(ccfullData.ALL9950.to_numpy().reshape(-1,1))\n",
    "ALL9950_onehot = pd.DataFrame(ALL9950_onehot, columns= onehot.get_feature_names(['ALL9950']))\n",
    "\n",
    "onehot.fit(ccfullData.ALL9951.to_numpy().reshape(-1,1))\n",
    "ALL9951_onehot = onehot.transform(ccfullData.ALL9951.to_numpy().reshape(-1,1))\n",
    "ALL9951_onehot = pd.DataFrame(ALL9951_onehot, columns= onehot.get_feature_names(['ALL9951']))\n",
    "\n",
    "onehot.fit(ccfullData.GLBDECS.to_numpy().reshape(-1,1))\n",
    "GLBDECS_onehot = onehot.transform(ccfullData.GLBDECS.to_numpy().reshape(-1,1))\n",
    "GLBDECS_onehot = pd.DataFrame(GLBDECS_onehot, columns= onehot.get_feature_names(['GLBDECS']))\n",
    "\n",
    "#Credit bureau attributes with Rank unit\n",
    "onehot.fit(ccfullData.ALL6310.to_numpy().reshape(-1,1))\n",
    "ALL6310_onehot = onehot.transform(ccfullData.ALL6310.to_numpy().reshape(-1,1))\n",
    "ALL6310_onehot = pd.DataFrame(ALL6310_onehot, columns= onehot.get_feature_names(['ALL6310']))\n",
    "\n",
    "onehot.fit(ccfullData.ALL6320.to_numpy().reshape(-1,1))\n",
    "ALL6320_onehot = onehot.transform(ccfullData.ALL6320.to_numpy().reshape(-1,1))\n",
    "ALL6320_onehot = pd.DataFrame(ALL6320_onehot, columns= onehot.get_feature_names(['ALL6320']))\n",
    "\n",
    "onehot.fit(ccfullData.MTF6326.to_numpy().reshape(-1,1))\n",
    "MTF6326_onehot = onehot.transform(ccfullData.MTF6326.to_numpy().reshape(-1,1))\n",
    "MTF6326_onehot = pd.DataFrame(MTF6326_onehot, columns= onehot.get_feature_names(['MTF6326']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dataframes = pd.concat(\n",
    "    [\n",
    "        year_onehot.reset_index(drop=True),\n",
    "        product_term_onehot.reset_index(drop=True),\n",
    "        cash_intent_onehot.reset_index(drop=True),\n",
    "        ALL9950_onehot.reset_index(drop=True),\n",
    "        ALL9951_onehot.reset_index(drop=True),\n",
    "        GLBDECS_onehot.reset_index(drop=True),\n",
    "        ALL6310_onehot.reset_index(drop=True),\n",
    "        ALL6320_onehot.reset_index(drop=True),\n",
    "        MTF6326_onehot.reset_index(drop=True),\n",
    "        scaler_df.reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1,\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "concatenated_dataframes_columns = [\n",
    "    list(year_onehot.columns),\n",
    "    list(product_term_onehot.columns),\n",
    "    list(cash_intent_onehot.columns),\n",
    "    list(ALL9950_onehot.columns),\n",
    "    list(ALL9951_onehot.columns),\n",
    "    list(GLBDECS_onehot.columns),\n",
    "    list(ALL6310_onehot.columns),\n",
    "    list(ALL6320_onehot.columns),\n",
    "    list(MTF6326_onehot.columns),\n",
    "    list(scaler_df.columns)\n",
    "]\n",
    "    \n",
    "flatten = lambda nested_lists: [item for sublist in nested_lists for item in sublist]\n",
    "\n",
    "concatenated_dataframes.columns = flatten(concatenated_dataframes_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['NP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from statistics import mean, stdev\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score, recall_score,auc,roc_curve\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = concatenated_dataframes\n",
    "Y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portfolio_id_1909</th>\n",
       "      <th>portfolio_id_1910</th>\n",
       "      <th>portfolio_id_1912</th>\n",
       "      <th>portfolio_id_2001</th>\n",
       "      <th>portfolio_id_2002</th>\n",
       "      <th>portfolio_id_2003</th>\n",
       "      <th>portfolio_id_2006</th>\n",
       "      <th>portfolio_id_2007</th>\n",
       "      <th>portfolio_id_2008</th>\n",
       "      <th>portfolio_id_2009</th>\n",
       "      <th>...</th>\n",
       "      <th>2309</th>\n",
       "      <th>2310</th>\n",
       "      <th>2311</th>\n",
       "      <th>2312</th>\n",
       "      <th>2313</th>\n",
       "      <th>2314</th>\n",
       "      <th>2315</th>\n",
       "      <th>2316</th>\n",
       "      <th>2317</th>\n",
       "      <th>2318</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.299613</td>\n",
       "      <td>-1.299623</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299647</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299673</td>\n",
       "      <td>-1.299613</td>\n",
       "      <td>-1.299613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.299613</td>\n",
       "      <td>-1.299623</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299647</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299612</td>\n",
       "      <td>-1.299673</td>\n",
       "      <td>-1.299613</td>\n",
       "      <td>-1.299613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769332</td>\n",
       "      <td>0.769460</td>\n",
       "      <td>0.769460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   portfolio_id_1909  portfolio_id_1910  portfolio_id_1912  portfolio_id_2001  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   portfolio_id_2002  portfolio_id_2003  portfolio_id_2006  portfolio_id_2007  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   portfolio_id_2008  portfolio_id_2009  ...      2309      2310      2311  \\\n",
       "0                0.0                0.0  ... -1.299613 -1.299623 -1.299612   \n",
       "1                0.0                0.0  ...  0.769460  0.769332  0.769460   \n",
       "2                0.0                0.0  ... -1.299613 -1.299623 -1.299612   \n",
       "3                0.0                0.0  ...  0.769460  0.769332  0.769460   \n",
       "4                0.0                0.0  ...  0.769460  0.769332  0.769460   \n",
       "\n",
       "       2312      2313      2314      2315      2316      2317      2318  \n",
       "0 -1.299612 -1.299647 -1.299612 -1.299612 -1.299673 -1.299613 -1.299613  \n",
       "1  0.769460  0.769332  0.769460  0.769460  0.769332  0.769460  0.769460  \n",
       "2 -1.299612 -1.299647 -1.299612 -1.299612 -1.299673 -1.299613 -1.299613  \n",
       "3  0.769460  0.769332  0.769460  0.769460  0.769332  0.769460  0.769460  \n",
       "4  0.769460  0.769332  0.769460  0.769460  0.769332  0.769460  0.769460  \n",
       "\n",
       "[5 rows x 2368 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_nb\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "        ..\n",
       "19026    1\n",
       "19027    1\n",
       "19028    1\n",
       "19029    1\n",
       "19030    1\n",
       "Name: NP, Length: 19030, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19030, 2368)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19030, 2368)\n",
      "(34610, 2368)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_oversample, y_oversample = ros.fit_resample(X, Y)\n",
    "print(X.shape)\n",
    "print(X_oversample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_oversample\n",
    "Y = y_oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracies for Logistic Regression is: [0.7903785  0.79196764 0.78532216 0.79023404 0.79110084]\n",
      "List of possible Precision for Logistic Regression is: [0.78486395 0.79469233 0.78109878 0.78906475 0.78662873]\n",
      "List of possible Recall for Logistic Regression is: [0.80005779 0.7873447  0.79283444 0.79225657 0.79890205]\n",
      "List of possible F1 score for Logistic Regression is: [0.79238804 0.79100145 0.78692286 0.79065744 0.79271789]\n",
      "List of possible ROC_AUC for Logistic Regression is: [0.87660639 0.87686902 0.87565468 0.8763602  0.87681518]\n",
      "Logistic Regression: 0.789801 (0.002322)\n",
      "---Classifier Logistic Regression use 214.3215 seconds ---\n",
      "List of possible accuracies for XGBoost is: [0.97139555 0.96836175 0.97211789 0.97341809 0.97341809]\n",
      "List of possible Precision for XGBoost is: [0.94686387 0.94072866 0.94718117 0.95075653 0.95075653]\n",
      "List of possible Recall for XGBoost is: [0.99884426 0.99971107 1.         0.99855533 0.99855533]\n",
      "List of possible F1 score for XGBoost is: [0.97215973 0.96932343 0.97287421 0.9740699  0.9740699 ]\n",
      "List of possible ROC_AUC for XGBoost is: [0.99655358 0.99536237 0.9972707  0.99721602 0.99659415]\n",
      "XGBoost: 0.971742 (0.001860)\n",
      "---Classifier XGBoost use 1163.3811 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA used</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.972499</td>\n",
       "      <td>0.996599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7898</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.790738</td>\n",
       "      <td>0.876461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MLA used  Test Accuracy  Precision  Recall        f1   roc_auc\n",
       "1              XGBoost         0.9717     0.9473  0.9991  0.972499  0.996599\n",
       "0  Logistic Regression         0.7898     0.7873  0.7943  0.790738  0.876461"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "row_index = 0\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('XGBoost', XGBClassifier(eval_metric='mlogloss')))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Create StratifiedKFold object.    \n",
    "tic = time.perf_counter()\n",
    "for name, model in models:\n",
    "    skfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X, Y, cv=skfold, scoring=scoring)\n",
    "    f1_results = model_selection.cross_val_score(model, X, Y, cv=skfold, scoring='f1')\n",
    "    recall_results = model_selection.cross_val_score(model, X, Y, cv=skfold, scoring='recall')\n",
    "    precision_results = model_selection.cross_val_score(model, X, Y, cv=skfold, scoring='precision')\n",
    "    roc_auc_results = model_selection.cross_val_score(model, X, Y, cv=skfold, scoring='roc_auc')\n",
    "    MLA_compare.loc[row_index,'MLA used'] = name\n",
    "    MLA_compare.loc[row_index, 'Test Accuracy'] = round(mean(cv_results), 4)\n",
    "    MLA_compare.loc[row_index, 'Precision'] = round(mean(precision_results),4)\n",
    "    MLA_compare.loc[row_index, 'Recall'] = round(mean(recall_results),4)\n",
    "    MLA_compare.loc[row_index, 'f1'] = mean(f1_results)\n",
    "    MLA_compare.loc[row_index, 'roc_auc'] = mean(roc_auc_results)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    # Print the output.\n",
    "    print('List of possible accuracies for {0} is: {1}'.format(name, cv_results))\n",
    "    print('List of possible Precision for {0} is: {1}'.format(name, precision_results))\n",
    "    print('List of possible Recall for {0} is: {1}'.format(name, recall_results))\n",
    "    print('List of possible F1 score for {0} is: {1}'.format(name, f1_results))\n",
    "    print('List of possible ROC_AUC for {0} is: {1}'.format(name, roc_auc_results))\n",
    "    msg = \"%s: %f (%f)\" % (name, mean(cv_results), cv_results.std())\n",
    "    print(msg)\n",
    "    toc = time.perf_counter()\n",
    "    secs = toc - tic\n",
    "    print(\"---Classifier %s use %0.4f seconds ---\" %(name, secs))\n",
    "    row_index+=1\n",
    "    \n",
    "MLA_compare.sort_values(by = ['Test Accuracy'], ascending = False, inplace = True)    \n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating plot to show the train accuracy\n",
    "plt.subplots(figsize=(5,5))\n",
    "sns.barplot(x=\"MLA used\", y=\"Test Accuracy\",data=MLA_compare,palette='Set2',edgecolor=sns.color_palette('Accent',7))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('MLA Test Accuracy Comparison')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
